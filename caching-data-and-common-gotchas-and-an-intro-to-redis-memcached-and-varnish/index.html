<!DOCTYPE html>
<html lang="en-US">
    <head>
        <meta charset="utf-8"> 
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="john pfeiffer" />
        <meta name="copyright" content="john pfeiffer" />

<meta name="keywords" content="cache, caching, redis, memcached, varnish, programming, " />
        <title>Caching data and common gotchas and an intro to redis memcached and varnish  · johnpfeiffer
</title>
        <!--link href="https://cdn-images.mailchimp.com/embedcode/slim-081711.css" rel="stylesheet" type="text/css"-->
        <!--link href="https://netdna.bootstrapcdn.com/twitter-bootstrap/2.3.1/css/bootstrap-combined.min.css" rel="stylesheet"-->
        <link href="https://blog.john-pfeiffer.com/theme/css/bootstrap-combined.min.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="https://blog.john-pfeiffer.com/theme/css/style.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://blog.john-pfeiffer.com/theme/css/solarizedlight.css" media="screen">
        <link rel="shortcut icon" href="https://blog.john-pfeiffer.com/theme/images/favicon.ico" type="image/x-icon" />
        <link rel="apple-touch-icon" href="https://blog.john-pfeiffer.com/theme/images/apple-touch-icon.png" />
        <link rel="apple-touch-icon" sizes="57x57" href="https://blog.john-pfeiffer.com/theme/images/apple-touch-icon-57x57.png" />
        <link rel="apple-touch-icon" sizes="72x72" href="https://blog.john-pfeiffer.com/theme/images/apple-touch-icon-72x72.png" />
        <link rel="apple-touch-icon" sizes="114x114" href="https://blog.john-pfeiffer.com/theme/images/apple-touch-icon-114x114.png" />
        <link rel="apple-touch-icon" sizes="144x144" href="https://blog.john-pfeiffer.com/theme/images/apple-touch-icon-144x144.png" />
        <link rel="icon" href="https://blog.john-pfeiffer.com/theme/images/apple-touch-icon-144x144.png" />
    </head>
    <body>
	<div id="content-sans-footer">
        <div class="dropdown-backdrop">

			<div class="navbar navbar-static-top">
				<div class="navbar-inner">
					<div class="container">
						<a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
						</a>
						<a class="brand" href="https://blog.john-pfeiffer.com/"><span class=site-name>johnpfeiffer</span></a>
						<div class="nav-collapse collapse">
							<ul class="nav pull-right top-menu">
								<li ><a href="https://blog.john-pfeiffer.com">Home</a></li>
								<li ><a href="https://blog.john-pfeiffer.com/john-likes/">John Likes</a></li>
								<li ><a href="https://blog.john-pfeiffer.com/categories.html">Categories</a></li>
								<li ><a href="https://blog.john-pfeiffer.com/tags.html">Tags</a></li>
								<li ><a href="https://blog.john-pfeiffer.com/archives.html">Archives</a></li>
								<li><form class="navbar-search" action="https://blog.john-pfeiffer.com/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
							</ul>
						</div>
					</div>
				</div>
			</div>
		</div>
		<div class="container-fluid">
			<div class="row-fluid">
				<div class="span1"></div>
				<div class="span10">
<article>
<div class="row-fluid">
    <header class="page_header span10 offset2">
    <h1><a href="https://blog.john-pfeiffer.com/caching-data-and-common-gotchas-and-an-intro-to-redis-memcached-and-varnish/"> Caching data and common gotchas and an intro to redis memcached and varnish  </a></h1>
    </header>
</div>

<div class="row-fluid">
    <div class="span2 table-of-content">
        <nav>
        <h4>Contents</h4>
        <div class="toc">
<ul>
<li><a href="#why-cache">Why Cache?</a><ul>
<li><a href="#questions-to-ask-when-caching">Questions to ask when caching</a></li>
<li><a href="#cache-latency-times-in-perspective">Cache Latency Times in Perspective</a></li>
<li><a href="#caches-are-another-operational-component-with-overhead">Caches are another Operational component with Overhead</a></li>
</ul>
</li>
<li><a href="#high-level-caching-for-the-application-versus-low-level-caching-for-the-persistence-layer">"High Level" caching for the application versus "Low Level" caching for the persistence layer</a></li>
<li><a href="#how-to-cache">How to Cache</a><ul>
<li><a href="#cache-on-write">Cache on Write</a></li>
<li><a href="#cache-on-read">Cache on Read</a></li>
<li><a href="#cache-warming">Cache Warming</a></li>
<li><a href="#flush-the-cache">Flush the Cache</a></li>
</ul>
</li>
<li><a href="#common-gotchas">Common Gotchas</a><ul>
<li><a href="#cache-on-write-gotchas">Cache on write gotchas</a></li>
<li><a href="#expiration-a-cache-full-of-stale-junk">Expiration: a cache full of stale junk</a></li>
<li><a href="#cold-cache-and-the-thundering-herd">Cold Cache and the Thundering Herd</a></li>
<li><a href="#upgrading-your-application">Upgrading your application</a></li>
<li><a href="#spanning-multiple-keys">Spanning Multiple Keys</a></li>
</ul>
</li>
<li><a href="#tools-for-caching">Tools for caching</a><ul>
<li><a href="#memcached">Memcached</a></li>
<li><a href="#redis-examples">Redis Examples</a></li>
<li><a href="#installing-redis">Installing Redis</a><ul>
<li><a href="#interactive-redis-prompt">Interactive Redis Prompt</a></li>
<li><a href="#non-interactive-redis-commands">Non Interactive Redis Commands</a></li>
<li><a href="#redis-clients">Redis Clients</a></li>
</ul>
</li>
<li><a href="#varnish">Varnish</a></li>
</ul>
</li>
</ul>
</div>
        </nav>
    </div>
    <div class="span8 article-content">

            
<p><strong>Caching is when you use a copy of a data set rather than using the original source.</strong></p>
<p>Caching often involves a "Key Value Lookup":</p>
<ol>
<li>A request is received and the service checks the cache using a Key</li>
<li>The cache does not contain the Key</li>
<li>The service generates the result from the originating data source (i.e. database)</li>
<li>The service then stores the result in the cache with the Key as the index (and the result as the Value)</li>
<li>A subsequent request is received and the service checks (looks up) the cache using a Key</li>
<li>The cache <strong>does</strong> contain the Key</li>
<li>The service retrieves the Value from the cache and returns the result</li>
</ol>
<p>A more concrete example would be to cache a User object by Email, so that whenever a request came in for a particular Users details the cache would contain their Name, Address, and Phone Number.</p>
<p><a href="https://en.wikipedia.org/wiki/Associative_array">https://en.wikipedia.org/wiki/Associative_array</a></p>
<h2 id="why-cache">Why Cache?</h2>
<p>A tradeoff of memory for cpu (or latency or some other business cost).</p>
<ul>
<li>computation is expensive (in terms of cpu, time, or money)</li>
<li>accessing the data from source is too slow</li>
<li>access to data across a larger geographic distance</li>
<li>the data actually comes from multiple sources (complex and expensive to retrieve)</li>
<li>to reduce load on the service originating data</li>
<li>to reduce contention (i.e. reads not served from the same persistence that does writes)</li>
<li>server side caching can protect backend resources and improve throughput and performance</li>
<li>for a client-server architecture, caching on the client reduces the number of required connections to a server</li>
</ul>
<h3 id="questions-to-ask-when-caching">Questions to ask when caching</h3>
<ul>
<li>Is the complexity of caching worth the performance gain? (a simpler implementation is often better, less chance of bugs!)</li>
<li>Does my cache need to be consistent? (meaning the cache and data source return identical results)</li>
<li>Can my cache be "eventually consistent"? (meaning a wrong answer for some specified period of time is ok)</li>
<li>Am I caching at a high level? (meaning aggregating a lot of work/responses from lower level systems)</li>
<li>Am I caching at a low level? (meaning inside of my Data Access Object pattern I'm protecting a single simple resource, i.e. a MySQL table, from being accessed too often)</li>
<li>How unique are my Keys in my cache (i.e. if multiple users can have the same identifier it would be very bad to return the wrong session to the wrong user)</li>
<li>Do I have the ability to operate or pay for a caching service?</li>
<li>What will happen if the cache is unavailable?</li>
</ul>
<h3 id="cache-latency-times-in-perspective">Cache Latency Times in Perspective</h3>
<p>Taking "why cache" to another level, the relative speeds of different cache levels highlight why some applications or algorithms will fail if they do not leverage cache.</p>
<ul>
<li>If your application uses a very large amount of data the network may actually be better than disk; optimization would probably not be focused on "loop unrolling"</li>
<li>If your application depends on data across the internet then network caching, routing algorithms, and data modeling (eventual consistency!) may be more important than "tail recursion vs iterative"</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align: center;">Action</th>
<th style="text-align: center;">nanoseconds</th>
<th style="text-align: center;">microseconds</th>
<th style="text-align: center;">milliseconds</th>
<th style="text-align: center;">human scale comparison</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">A typical cpu instruction</td>
<td style="text-align: center;">1 ns</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">1 second basis (approximations)</td>
</tr>
<tr>
<td style="text-align: center;">L1 cache fetch</td>
<td style="text-align: center;">0.5 ns</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Branch misprediction</td>
<td style="text-align: center;">4 ns</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">L2 cache fetch</td>
<td style="text-align: center;">7 ns</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">7 seconds</td>
</tr>
<tr>
<td style="text-align: center;">Mutex lock/unlock</td>
<td style="text-align: center;">25 ns</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">RAM "main memory" fetch</td>
<td style="text-align: center;">100 ns</td>
<td style="text-align: center;">0.1 us</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">2 minutes</td>
</tr>
<tr>
<td style="text-align: center;">Read 4K randomly from SSD</td>
<td style="text-align: center;">100,000 ns</td>
<td style="text-align: center;">100 us</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">28 hours</td>
</tr>
<tr>
<td style="text-align: center;">Read 1 MB sequentially from memory</td>
<td style="text-align: center;">250,000 ns</td>
<td style="text-align: center;">250 us</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">3 days</td>
</tr>
<tr>
<td style="text-align: center;">Send 1000 bytes over 1 Gbps network</td>
<td style="text-align: center;">500,000 ns</td>
<td style="text-align: center;">500 us</td>
<td style="text-align: center;">0.5 ms</td>
<td style="text-align: center;">6 days</td>
</tr>
<tr>
<td style="text-align: center;">Read 1 MB sequentially from SSD</td>
<td style="text-align: center;">1,000,000 ns</td>
<td style="text-align: center;">1,000 us</td>
<td style="text-align: center;">1 ms</td>
<td style="text-align: center;">12 days</td>
</tr>
<tr>
<td style="text-align: center;">Spinning Hard Disk seek</td>
<td style="text-align: center;">8,000,000 ns</td>
<td style="text-align: center;">8,000 us</td>
<td style="text-align: center;">8 ms</td>
<td style="text-align: center;">3 months</td>
</tr>
<tr>
<td style="text-align: center;">Read 1 MB sequentially from disk</td>
<td style="text-align: center;">20,000,000 ns</td>
<td style="text-align: center;">20,000 us</td>
<td style="text-align: center;">20 ms</td>
<td style="text-align: center;">7.6 months</td>
</tr>
<tr>
<td style="text-align: center;">Packet Roundtrip SF to NY</td>
<td style="text-align: center;">70,000,000 ns</td>
<td style="text-align: center;">70,000 us</td>
<td style="text-align: center;">70 ms</td>
<td style="text-align: center;">2 years</td>
</tr>
<tr>
<td style="text-align: center;">Packet Roundtrip SF to NY</td>
<td style="text-align: center;">150,000,000 ns</td>
<td style="text-align: center;">150,000 us</td>
<td style="text-align: center;">150 ms</td>
<td style="text-align: center;">5 years</td>
</tr>
</tbody>
</table>
<blockquote>
<p>The L1 cache is the memory cache integrated into the CPU that is closest</p>
<p>Light travels 30 cm or about 1 foot in 1 nanosecond</p>
<p>ns = nanoseconds, us = microseconds, ms = milliseconds</p>
</blockquote>
<ul>
<li><a href="http://norvig.com/21-days.html#answers">http://norvig.com/21-days.html#answers</a> (Peter Norvig) </li>
<li><a href="https://en.wikipedia.org/wiki/CPU_cache">https://en.wikipedia.org/wiki/CPU_cache</a></li>
<li><a href="https://en.wikipedia.org/wiki/Solid-state_drive#Controller">https://en.wikipedia.org/wiki/Solid-state_drive#Controller</a></li>
<li><a href="http://www.codingblocks.net/podcast/episode-45-caching-overview-and-hardware/">http://www.codingblocks.net/podcast/episode-45-caching-overview-and-hardware/</a></li>
<li><a href="https://wondernetwork.com/pings">https://wondernetwork.com/pings</a></li>
<li><a href="https://twitter.com/rzezeski/status/398306728263315456/photo/1">https://twitter.com/rzezeski/status/398306728263315456/photo/1</a> (Brendan Gregg)</li>
</ul>
<h3 id="caches-are-another-operational-component-with-overhead">Caches are another Operational component with Overhead</h3>
<p>The best advice is to definitely avoiding caching until the last possible moment (<em>"less is the best" and "premature optimization" and "be future flexible" and "defer architecture decisions"</em>)</p>
<p>Not only do you have to write code complexity for using a cache, there's the nitty gritty of running a cache (which can be a completely different expertise than programming)</p>
<ul>
<li>Install</li>
<li>Deployment</li>
<li>Upgrades</li>
<li>Security</li>
<li>Monitoring</li>
<li>Metrics</li>
<li>Testing (i.e. synthetic smoke tests or load)</li>
</ul>
<p>None of this operational cost is free, and there are plenty of issues when just implementing caching in the code...</p>
<h2 id="high-level-caching-for-the-application-versus-low-level-caching-for-the-persistence-layer">"High Level" caching for the application versus "Low Level" caching for the persistence layer</h2>
<p>Caching can be the most effective at the "highest" layer where the application is able to trivially service a request.  (e.g. caching the final full web page that was requested)</p>
<p>This "protects" all of the underlying machinery from having to do work.  It requires a good understanding of how dynamic or personalized the results are, designing the system to have pieces that can be cached, and is brittle to change.</p>
<p>Caching can be an "easy win" when applied at the "lowest" layer right near the persistence (i.e. redis "in front of" a database - that for example contains the new articles that will be served on a web page) as all of the components in layers above can benefit from improved performance without having to change the business logic (or perhaps even unaware of the caching).</p>
<p>Both can be used together but to paraphrase: "mo caching mo problems"</p>
<h2 id="how-to-cache">How to Cache</h2>
<h3 id="cache-on-write">Cache on Write</h3>
<p>Also known as "cache on write through", whenever new data is written a cache must also be updated.</p>
<h3 id="cache-on-read">Cache on Read</h3>
<p>Also known as "cache on read through", whenever a query is made first the cache is checked.</p>
<ul>
<li>If there is a "cache miss" then the data source is queried and the cache is updated and the result is returned.  </li>
<li>If there is a "cache hit" and the data is in the cache then it is returned (and potentially a cache key expiration updated as this cache hit improved the cache efficiency).</li>
</ul>
<h3 id="cache-warming">Cache Warming</h3>
<p>Pre-emptively adding data to the cache is "cache warming" in order to improve "cache hit" percentages and reduce the risk of "cold cache" issues.</p>
<h3 id="flush-the-cache">Flush the Cache</h3>
<p>Removing some or all data from the cache in order to invalidate a chunk of data (i.e. all users need to reset their passwords) or pre-emptively free up memory/space.</p>
<h2 id="common-gotchas">Common Gotchas</h2>
<p>Caching is challenging because of the need for data consistency, parallel requests, and race conditions.</p>
<p>One good way to think about it is a banking system with money...</p>
<blockquote>
<p>If two people both try to empty a bank account at an ATM at the same time how will your caching system handle it?</p>
</blockquote>
<h3 id="cache-on-write-gotchas">Cache on write gotchas</h3>
<ul>
<li>There may be a design mismatch as since data is only cached on write, if reads are occurring mostly on data written a long time ago they will be expired/pushed out and you will have poor cache efficiency (paradoxically adding caching will have resulted in more complexity and worse performance).</li>
<li>One implementation flaw is updating the cache first; if the update to the data source fails then some requests may have been given incorrect data.</li>
<li>The opposite order of updating the canonical source first can have a similar problem if the process fails before the cache can be updated. (Thus leaving the cache with old data).</li>
<li>
<ul>
<li>First invalidating the cache reduces the risk of a failure during a write creating an inconsistent state</li>
</ul>
</li>
<li>
<ul>
<li>Next update the data persistence (which should be provided as an atomic operation by your vendor ;)</li>
</ul>
</li>
<li>
<ul>
<li>Finally update the cache</li>
</ul>
</li>
<li>
<ul>
<li>In the worst case the canonical source will be updated without the benefit of caching</li>
</ul>
</li>
<li>
<ul>
<li>One might also have a "transaction" defined around both the update of the origin and cache with retries for failure</li>
</ul>
</li>
<li>While "cache on write" is a sometimes band-aid for NoSQL "eventual consistency" when it fails (i.e. all applications should expect that a cache will not exist or have a cache miss) the result may be data inconsistency.</li>
<li>
<ul>
<li>One workaround is "check and set" (or "compare and set") where the cache will auto-invalidate if two conflicting entries are attempted.</li>
</ul>
</li>
<li>
<ul>
<li><a href="https://neopythonic.blogspot.com/2011/08/compare-and-set-in-memcache.html">https://neopythonic.blogspot.com/2011/08/compare-and-set-in-memcache.html</a></li>
</ul>
</li>
</ul>
<blockquote>
<p>This "gotcha" could be summarized as not handling rollback</p>
</blockquote>
<h3 id="expiration-a-cache-full-of-stale-junk">Expiration: a cache full of stale junk</h3>
<p>A naive implementation of caching will store every result in the cache forever...</p>
<p>While this seems like a good idea (<em>"The cache application/service will just evict unused items based some algorithm"</em>) it is essentially forcing your cache to be full of potentially low value information on the hope that someone else will solve the problem.</p>
<p>Since some caching tools/framework do not set a default <strong>Time To Live</strong> or <strong>Expiration</strong> and in that case all of your data may quickly fill up the cache (not a bad thing per se), but then it will use whatever default or global "eviction policy" that is defined.</p>
<p>Even O(1) can be broken by a pathological data set, and keeping every item seems like a good way to find an edge case (i.e. hash collisions and chaining).</p>
<p>Applying business logic and empirical data to pick sane expiration values might not only improve cache performance but may protect your service from security issues or bugs due to serving really stale data.</p>
<blockquote>
<p>e.g. for security reasons, <strong>caching a session "forever" is a bad idea</strong> as an attacker may get access to an old client cache or token and be able to impersonate a legimate user</p>
</blockquote>
<p>Issues with Expiration Set Too Long:</p>
<ul>
<li>Security concerns</li>
<li>Lack of control/non determinism for when and what items might be evicted</li>
<li>Poor performance, memory pressure, and possibly increased operational cost</li>
<li>Stale data</li>
<li>Large cache sizes may end up writing to disk (i.e. redis sync to disk may use copy on write)</li>
</ul>
<p><strong>Set a TTL or Expiration, whenever possible, that matches your domain</strong> (i.e. for a session 1 day or 1 week).</p>
<blockquote>
<p>If the Time to Live is too short then the cache may have very poor efficiency (items expire before they can generate even one cache hit), meaning all of the coding and operational cost are for nothing =[</p>
</blockquote>
<h3 id="cold-cache-and-the-thundering-herd">Cold Cache and the Thundering Herd</h3>
<ol>
<li>If the cache is "cold", i.e. has not been populated, then all queries will go directly to the source</li>
<li>If the source is not prepared for the "thundering herd" of requests (that were usually handled by the cache) then the source may become overloaded and bad things will happen</li>
<li>It is therefore best practice to "warm the cache" by seeding data from the source into the cache before significant load events</li>
</ol>
<p>Cold cache not only can cause problems from the source but when lot of data is written simultaneously to the cache, if the cache uses underlying disk or some other IO resource, it may temporarily overwhelm the cache (system/framework).</p>
<h3 id="upgrading-your-application">Upgrading your application</h3>
<p>In a sense the cache layer is an external persistence that has to stay in sync with the application code; they are logically and semantically bound together.</p>
<p>Modification to your application code, specifically the way it reads and writes to the cache, may return "bad" data.</p>
<ol>
<li>Cache key "admins" stored a list of usernames of admin users for the application</li>
<li>Cache key "ausers" stored a list of usernames that begin with the letter "a"</li>
<li>An application upgrade occurs</li>
<li>Now the code has a bug that looks up "ausers" in order to give administrator permssions</li>
<li>(oops)</li>
</ol>
<h3 id="spanning-multiple-keys">Spanning Multiple Keys</h3>
<p>If you need to retrieve multiple items from a cache in order to fulfill a request you may run the risk of "torn reads" where the first item retrieved from cache is logically inconsistent with the second item.</p>
<h2 id="tools-for-caching">Tools for caching</h2>
<p>Much like encryption it is probably a good idea to use a time tested caching component over writing your own implementation.</p>
<p>A local in memory cache is a tried and true way of speeding up an application but it may not provide the transparency and visibility when there are bugs.</p>
<p>While it seems trivial to setup it will slow down your dev velocity on your high value focus area and every new feature you realize you need (automatic expiration, authentication, etc.) will create a distraction and eventual maintenance requirement.</p>
<p>Instead there are quite a few very popular battle tested options...</p>
<h3 id="memcached">Memcached</h3>
<ul>
<li><a href="http://memcached.org">http://memcached.org</a></li>
<li><a href="https://en.wikipedia.org/wiki/Memcached">https://en.wikipedia.org/wiki/Memcached</a></li>
<li><a href="https://hub.docker.com/r/_/memcached/">https://hub.docker.com/r/_/memcached/</a></li>
</ul>
<p><code>docker run --rm -it --publish 11211:11211 --name mymemcached memcached:alpine</code></p>
<div class="highlight"><pre><span></span><code>echo -e 'add foo 0 60 11\r\nhello world\r' | nc localhost 11211
telnet localhost 11211
get foo
</code></pre></div>
<blockquote>
<p>VALUE foo 0 11
hello world</p>
</blockquote>
<p><a href="https://github.com/memcached/memcached/wiki/Commands">https://github.com/memcached/memcached/wiki/Commands</a></p>
<h3 id="redis-examples">Redis Examples</h3>
<p>Redis has surpassed memcached in terms of speed and functionality and if you need to store more than "just a string" you should experiment with it.</p>
<p>Besides having a cache to speed up lookups for your application or as a globally shared cache (be careful!) between multiple application serveers there can be a nice convenience as a "meta" persistence such that you can deploy a new version of your application and not lose all of the data in the cache.</p>
<p>One thing to think about is that local redis might be far more effective than remote over the network redis.</p>
<p>If your application can depend less shared state this is good because sharing is a nightmare for cache semantics and distributed computing.</p>
<blockquote>
<p>When possible avoid a globally shared cache between multiple processes or servers, or invest in learning about atomic operations</p>
</blockquote>
<p>Regardless of whether you securing your remote cache (or just depend on network isolation) you will always want to measure cache effectiveness.</p>
<h3 id="installing-redis">Installing Redis</h3>
<p>The simplest way is to use Docker, <a href="https://hub.docker.com/r/_/redis/">https://hub.docker.com/r/_/redis/</a></p>
<p><code>docker run --rm -it --publish 6379:6379 --name myredis redis:alpine</code>
<code>docker run -it --link myredis:redis --rm redis:alpine redis-cli -h redis -p 6379 set message hello</code>
<code>docker run -it --link myredis:redis --rm redis:alpine redis-cli -h redis -p 6379 get message</code></p>
<blockquote>
<p>run an ephemeral docker container and then non-interactively use the same docker image to set and get a string key</p>
</blockquote>
<p>If you prefer installing locally to your filesystem or server:</p>
<ul>
<li><a href="https://redis.io/topics/quickstart">https://redis.io/topics/quickstart</a> (compiling from source)</li>
<li>
<p><a href="https://packages.ubuntu.com/trusty/redis-server">https://packages.ubuntu.com/trusty/redis-server</a> (sudo apt-get install redis-server)</p>
<p>redis-cli -h localhost:6379 ping</p>
<blockquote>
<p>PONG , aka verify a remote server connectivity</p>
</blockquote>
</li>
</ul>
<h4 id="interactive-redis-prompt">Interactive Redis Prompt</h4>
<div class="highlight"><pre><span></span><code>redis-cli
keys *
</code></pre></div>
<h4 id="non-interactive-redis-commands">Non Interactive Redis Commands</h4>
<div class="highlight"><pre><span></span><code>redis-cli KEYS *:*
</code></pre></div>
<blockquote>
<p>non-interactively get all of the keys that have subkeys</p>
</blockquote>
<div class="highlight"><pre><span></span><code>redis-cli KEYS "session:3:*" | xargs redis-cli DEL
</code></pre></div>
<blockquote>
<p>non-interactively delete/remove all of the subkeys under the sub subkey</p>
</blockquote>
<div class="highlight"><pre><span></span><code>redis-cli KEYS session:1:*
redis-cli hgetall session:1:web
redis-cli hgetall session:1:web:presence

redis-cli KEYS session:1:*  | grep session:1:web-48
  session:1:web-48679:rooms
  session:1:web-48679:presence
  session:1:web-48679:message_ids
  session:1:web-48679

redis-cli zrange sessions:1 0 9
  1) "1:web"
  2) "1:web-48679"

redis-cli zrem sessions:1 1:web-48679
redis-cli del   session:1:web-48679:rooms
redis-cli del   session:1:web-48679:presence
redis-cli del   session:1:web-48679:message_ids
redis-cli del   session:1:web-48679
</code></pre></div>
<ul>
<li><a href="https://redis.io/commands">https://redis.io/commands</a></li>
</ul>
<h4 id="redis-clients">Redis Clients</h4>
<div class="highlight"><pre><span></span><code>pip install redis
</code></pre></div>
<blockquote>
<p><a href="http://redis.io/clients#python">http://redis.io/clients#python</a></p>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">redis</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">redis</span><span class="o">.</span><span class="n">StrictRedis</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="s1">'localhost'</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="mi">6379</span><span class="p">)</span>
<span class="n">r</span><span class="o">.</span><span class="n">flushall</span><span class="p">()</span>
</code></pre></div>
<blockquote>
<p><a href="https://pypi.python.org/pypi/redis">https://pypi.python.org/pypi/redis</a></p>
</blockquote>
<p><strong>Go</strong> <code>go get github.com/garyburd/redigo</code></p>
<div class="highlight"><pre><span></span><code><span class="kn">package</span><span class="w"> </span><span class="nx">main</span><span class="w"></span>

<span class="kn">import</span><span class="w"> </span><span class="p">(</span><span class="w"></span>
<span class="w">    </span><span class="s">"fmt"</span><span class="w"></span>

<span class="w">    </span><span class="s">"github.com/garyburd/redigo/redis"</span><span class="w"></span>
<span class="p">)</span><span class="w"></span>

<span class="kd">func</span><span class="w"> </span><span class="nx">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="nx">c</span><span class="p">,</span><span class="w"> </span><span class="nx">_</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">redis</span><span class="p">.</span><span class="nx">Dial</span><span class="p">(</span><span class="s">"tcp"</span><span class="p">,</span><span class="w"> </span><span class="s">":6379"</span><span class="p">)</span><span class="w"></span>
<span class="w">    </span><span class="k">defer</span><span class="w"> </span><span class="nx">c</span><span class="p">.</span><span class="nx">Close</span><span class="p">()</span><span class="w"></span>
<span class="w">    </span><span class="nx">c</span><span class="p">.</span><span class="nx">Do</span><span class="p">(</span><span class="s">"SET"</span><span class="p">,</span><span class="w"> </span><span class="s">"message"</span><span class="p">,</span><span class="w"> </span><span class="s">"hi"</span><span class="p">)</span><span class="w"></span>
<span class="w">    </span><span class="nx">s</span><span class="p">,</span><span class="w"> </span><span class="nx">_</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nx">redis</span><span class="p">.</span><span class="nx">String</span><span class="p">(</span><span class="nx">c</span><span class="p">.</span><span class="nx">Do</span><span class="p">(</span><span class="s">"GET"</span><span class="p">,</span><span class="w"> </span><span class="s">"message"</span><span class="p">))</span><span class="w"></span>
<span class="w">    </span><span class="nx">fmt</span><span class="p">.</span><span class="nx">Println</span><span class="p">(</span><span class="nx">s</span><span class="p">)</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</code></pre></div>
<p>A more complete example: <a href="https://bitbucket.org/johnpfeiffer/go-cache">https://bitbucket.org/johnpfeiffer/go-cache</a></p>
<h3 id="varnish">Varnish</h3>
<ul>
<li><a href="https://www.varnish-cache.org/about">https://www.varnish-cache.org/about</a> REST web caching</li>
</ul>
            <aside>
            <hr/>
            <nav>
            <ul class="articles_timeline">
 
                <li class="previous_article">« <a href="https://blog.john-pfeiffer.com/subunit-and-subunit2junitxml-to-get-junitxml-test-result-output-from-unittest/" title="Previous: Subunit and Subunit2JunitXML to get JUnitXML test result output from UnitTest">Subunit and Subunit2JunitXML to get JUnitXML test result output from UnitTest</a></li>
 
                <li class="next_article"><a href="https://blog.john-pfeiffer.com/haproxy-in-docker/" title="Next: HAProxy in Docker">HAProxy in Docker</a> »</li>
            </ul>
            </nav>
            </aside>
        </div>
        <section>
        <div class="span2" style="float:right;font-size:0.9em;">
 
            <h4>Published</h4>
            <time pubdate="pubdate" datetime="2015-03-26T00:00:00-07:00">Mar 26, 2015</time>
            <h4>Category</h4>
            <a class="category-link" href="/categories.html#programming-ref">programming</a> 
            <h4>~2501 words</h4>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article"> 
                <li><a href="/tags.html#cache-ref">cache
                    <span>1</span>
</a></li>
                <li><a href="/tags.html#caching-ref">caching
                    <span>1</span>
</a></li>
                <li><a href="/tags.html#memcached-ref">memcached
                    <span>1</span>
</a></li>
                <li><a href="/tags.html#redis-ref">redis
                    <span>1</span>
</a></li>
                <li><a href="/tags.html#varnish-ref">varnish
                    <span>1</span>
</a></li>
            </ul>

        </div>
        </section>
</div>
</article>
				</div>
				<div class="span1"></div>
			</div>
		</div>
    </div>
<footer>
<div id="footer">
    <ul class="footer-content">
    </ul>
</div>
</footer>            <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/2.3.1/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    </body>
</html>